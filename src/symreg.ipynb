{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:45.901204Z",
     "start_time": "2025-01-18T14:17:45.390822Z"
    }
   },
   "source": [
    "import os\n",
    "import operator\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f676310ac8a21314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:45.914238Z",
     "start_time": "2025-01-18T14:17:45.910824Z"
    }
   },
   "source": [
    "CONSTANT_PROBABILITY = 0.3\n",
    "OPERATOR_PROBABILITY = 0.6\n",
    "OPERATOR_FIRST_PROBABILITY = 0.9\n",
    "CONSTANT_RANGE = (-10, 10)\n",
    "\n",
    "cache = {}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1c1b1eb3cf62bb8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:45.934267Z",
     "start_time": "2025-01-18T14:17:45.920543Z"
    }
   },
   "source": [
    "class Node:\n",
    "    def evaluate(self, x):\n",
    "        raise NotImplementedError(\"Must implement evaluate method\")\n",
    "\n",
    "    def __str__(self):\n",
    "        raise NotImplementedError(\"Must implement __str__ method\")\n",
    "\n",
    "    def clone(self):\n",
    "        raise NotImplementedError(\"Must implement clone method\")\n",
    "\n",
    "    def from_string(self, string):\n",
    "        raise NotImplementedError(\"Must implement from_string method\")\n",
    "\n",
    "class OperatorNode(Node):\n",
    "    # Adding all NumPy mathematical functions to OPERATORS\n",
    "    OPERATORS = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        '/': lambda a, b: a / b if b != 0 else 1,  # Protected division\n",
    "        'sin': lambda x: np.sin(np.clip(x, -1e10, 1e10)),  # Clamp input to avoid invalid values\n",
    "        'cos': lambda x: np.cos(np.clip(x, -1e10, 1e10)),  # Clamp input to avoid invalid values\n",
    "        'tan': lambda x: np.tan(np.clip(x, -1e10, 1e10)),  # Clamp input to avoid invalid values\n",
    "        'log': lambda x: np.log(np.clip(x, 1e-10, None)),  # Avoid log(0) and negative values\n",
    "        'exp': lambda x: np.exp(np.clip(x, -700, 700)),\n",
    "        'sqrt': lambda x: np.sqrt(np.clip(x, 0, None)),  # Avoid sqrt of negative values\n",
    "        'abs': lambda x: np.abs(x),\n",
    "    }\n",
    "\n",
    "    BINARY_OPERATORS = {'+', '-', '*', '/'}\n",
    "\n",
    "    def __init__(self, operator_symbol, left=None, right=None, depth=0):\n",
    "        self.operator_symbol = operator_symbol\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.function = self.OPERATORS.get(operator_symbol)\n",
    "        self.depth = depth\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        # Evaluate left and right children\n",
    "        left_val = self.left.evaluate(x)\n",
    "        if self.operator_symbol not in self.BINARY_OPERATORS:\n",
    "            result = self.function(left_val)\n",
    "        else:\n",
    "            right_val = self.right.evaluate(x)\n",
    "            result = self.function(left_val, right_val)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __str__(self):\n",
    "        if not self.right:\n",
    "            return f\"{self.operator_symbol}({self.left})\"\n",
    "        return f\"({self.left} {self.operator_symbol} {self.right})\"\n",
    "\n",
    "    def clone(self):\n",
    "        return OperatorNode(\n",
    "            self.operator_symbol,\n",
    "            self.left.clone() if self.left else None,\n",
    "            self.right.clone() if self.right else None,\n",
    "            self.depth,\n",
    "        )\n",
    "\n",
    "    def get_depth(self):\n",
    "        left_depth = self.left.get_depth() if self.left else 0\n",
    "        right_depth = self.right.get_depth() if self.right else 0\n",
    "        return max(left_depth, right_depth)\n",
    "\n",
    "    def from_string(self, string):\n",
    "        # Parse the string to reconstruct the tree\n",
    "        stack = []\n",
    "        tokens = string.replace('(', ' ( ').replace(')', ' ) ').split()\n",
    "        for token in tokens:\n",
    "            if token == '(':\n",
    "                continue\n",
    "            elif token == ')':\n",
    "                right = stack.pop()\n",
    "                left = stack.pop()\n",
    "                op = stack.pop()\n",
    "                node = OperatorNode(op)\n",
    "                node.left = left\n",
    "                node.right = right\n",
    "                stack.append(node)\n",
    "            elif token in OperatorNode.OPERATORS:\n",
    "                stack.append(token)\n",
    "            else:\n",
    "                stack.append(OperandNode(float(token)) if token.replace('.', '', 1).isdigit() else OperandNode(token))\n",
    "        return stack[0]\n",
    "\n",
    "\n",
    "class OperandNode(Node):\n",
    "    def __init__(self, value, depth=0):\n",
    "        self.value = value  # Can be a constant or a variable\n",
    "        self.depth = depth\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        # Evaluate the operand (constant or variable)\n",
    "        if isinstance(self.value, str):\n",
    "            result = x[int(self.value.lstrip('x_'))]\n",
    "        else:\n",
    "            result = self.value\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "    def clone(self):\n",
    "        return OperandNode(self.value, self.depth)\n",
    "\n",
    "    def get_depth(self):\n",
    "        return self.depth + 1\n",
    "\n",
    "    def from_string(self, string):\n",
    "        return OperandNode(float(string) if string.replace('.', '', 1).isdigit() else string)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b91259d82a972a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.072116Z",
     "start_time": "2025-01-18T14:17:46.067176Z"
    }
   },
   "source": [
    "def generate_random_tree(max_depth, n_variables, current_depth=0, op=None):\n",
    "    def get_operator():\n",
    "        new_operator = random.choice(list(OperatorNode.OPERATORS.keys()))\n",
    "        left = generate_random_tree(max_depth, n_variables, current_depth + 1, new_operator)\n",
    "        right = None\n",
    "        if new_operator in OperatorNode.BINARY_OPERATORS:\n",
    "            right = generate_random_tree(max_depth, n_variables, current_depth + 1, new_operator)\n",
    "        new_node = OperatorNode(new_operator, left, right, current_depth)\n",
    "        return new_node\n",
    "\n",
    "\n",
    "    def get_operand():\n",
    "        if random.random() < CONSTANT_PROBABILITY:\n",
    "            value = random.uniform(*CONSTANT_RANGE)\n",
    "            value = round(value, 2)\n",
    "            return OperandNode(value, current_depth)\n",
    "        else:\n",
    "            return OperandNode('x_' + str(random.randint(0, n_variables-1)), current_depth)\n",
    "\n",
    "\n",
    "    if current_depth >= max_depth:\n",
    "        return get_operand()\n",
    "\n",
    "    elif current_depth == 0 and random.random() < OPERATOR_FIRST_PROBABILITY:\n",
    "        return get_operator()\n",
    "\n",
    "    elif random.random() < OPERATOR_PROBABILITY:\n",
    "        return get_operator()\n",
    "\n",
    "    return get_operand()\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.119263Z",
     "start_time": "2025-01-18T14:17:46.116214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_nodes(node):\n",
    "    nodes = [node]\n",
    "    if isinstance(node, OperatorNode):\n",
    "        nodes += get_all_nodes(node.left)\n",
    "        nodes += get_all_nodes(node.right)\n",
    "\n",
    "    return nodes"
   ],
   "id": "90ee1d129888bce8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "b40784a6dd8db4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.143533Z",
     "start_time": "2025-01-18T14:17:46.140293Z"
    }
   },
   "source": [
    "def initialize_population(pop_size, n_variables, max_depth=5):\n",
    "    population = np.array([generate_random_tree(max_depth, n_variables) for _ in range(pop_size)])\n",
    "    return population"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.169809Z",
     "start_time": "2025-01-18T14:17:46.158556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clear_cache():\n",
    "    cache.clear()\n",
    "\n",
    "\n",
    "def evaluate_individual(individual, x):\n",
    "    key = (individual, tuple(x))\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    result = individual.evaluate(x)\n",
    "    cache[key] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "def dominates(ind1: tuple[float, float], ind2: tuple[float, float]) -> bool:\n",
    "    return (ind1[0] <= ind2[0] and ind1[1] <= ind2[1]) and (ind1[0] < ind2[0] or ind1[1] < ind2[1])\n",
    "\n",
    "\n",
    "def pareto_front(population: list[Node], objectives: list[tuple[float, int]]) -> list[Node]:\n",
    "    front = []\n",
    "    for i, obj1 in enumerate(objectives):\n",
    "        dominated = False\n",
    "        for j, obj2 in enumerate(objectives):\n",
    "            if i != j and dominates(obj2, obj1):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            front.append(population[i])\n",
    "    return front\n",
    "\n",
    "\n",
    "def diversity_preserving_selection(front: list[Node], objectives: list[tuple[float, int]], count: int) -> list[Node]:\n",
    "    distances = [0] * len(front)\n",
    "\n",
    "    # Calculate crowding distance for each objective\n",
    "    for i, obj_values in enumerate(zip(*objectives)):\n",
    "        sorted_indices = sorted(range(len(front)), key=lambda x: obj_values[x])\n",
    "        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = float('inf')\n",
    "        for j in range(1, len(front) - 1):\n",
    "            distances[sorted_indices[j]] += obj_values[sorted_indices[j + 1]] - obj_values[sorted_indices[j - 1]]\n",
    "\n",
    "    # Select individuals with the highest crowding distance\n",
    "    sorted_indices = sorted(range(len(front)), key=lambda x: distances[x], reverse=True)\n",
    "    return [front[i] for i in sorted_indices[:count]]\n",
    "\n",
    "\n",
    "def get_objectives(individual: Node, X: np.ndarray, y: np.ndarray) -> tuple[Node, float, int]:\n",
    "    # Evaluate predictions for all samples in X\n",
    "    predictions = np.array([evaluate_individual(individual, tuple(x)) for x in X])\n",
    "\n",
    "    predictions_clipped = np.clip(predictions, -1e10, 1e10)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = np.mean((y - predictions_clipped) ** 2)\n",
    "\n",
    "    # Calculate complexity (number of nodes in the tree)\n",
    "    complexity = len(get_all_nodes(individual))\n",
    "\n",
    "    return individual, mse, complexity\n",
    "\n",
    "\n",
    "def multi_objective_selection(objectives: dict) -> list[Node]:\n",
    "    selected = []\n",
    "    remaining_pop = list(objectives.keys())\n",
    "    remaining_objectives = list(objectives.values())\n",
    "    pop_size = len(remaining_pop)\n",
    "\n",
    "    while len(selected) < pop_size:\n",
    "        # Find the next Pareto front\n",
    "        front = pareto_front(remaining_pop, remaining_objectives)\n",
    "\n",
    "        if len(selected) + len(front) <= pop_size:\n",
    "            selected.extend(front)\n",
    "        else:\n",
    "            # Use diversity-preserving selection if the front size exceeds remaining slots\n",
    "            selected.extend(diversity_preserving_selection(front, remaining_objectives, pop_size - len(selected)))\n",
    "            break\n",
    "\n",
    "        # Remove Pareto front solutions from the remaining population\n",
    "        for individual in front:\n",
    "            idx = remaining_pop.index(individual)\n",
    "            del remaining_pop[idx]\n",
    "            del remaining_objectives[idx]\n",
    "\n",
    "    return selected\n",
    "\n"
   ],
   "id": "6d089751097bf2b1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "5a9aac198d7f7263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.190710Z",
     "start_time": "2025-01-18T14:17:46.181986Z"
    }
   },
   "source": [
    "def crossover(parent1: Node, parent2: Node) -> tuple[Node, Node]:\n",
    "    parent1 = parent1.clone()\n",
    "    parent2 = parent2.clone()\n",
    "\n",
    "    # Get all nodes from both parents\n",
    "    nodes1 = get_all_nodes(parent1)\n",
    "    nodes2 = get_all_nodes(parent2)\n",
    "\n",
    "    # Randomly select crossover points\n",
    "    crossover_point1 = random.choice(nodes1)\n",
    "    while crossover_point1 is None:\n",
    "        crossover_point1 = random.choice(nodes1)\n",
    "\n",
    "    crossover_point2 = random.choice(nodes2)\n",
    "    while crossover_point2 is None:\n",
    "        crossover_point2 = random.choice(nodes2)\n",
    "\n",
    "    # Swap the subtrees if both crossover points are OperatorNodes\n",
    "    if isinstance(crossover_point1, OperatorNode) and isinstance(crossover_point2, OperatorNode):\n",
    "        swap_subtrees(crossover_point1, crossover_point2)\n",
    "    elif isinstance(crossover_point1, OperandNode) and isinstance(crossover_point2, OperandNode):\n",
    "        swap_operands(crossover_point1, crossover_point2)\n",
    "    else:\n",
    "        # Replace the subtree of one parent with the subtree of the other parent\n",
    "        replace_subtree(parent1, parent2, crossover_point1, crossover_point2)\n",
    "\n",
    "    return parent1, parent2\n",
    "\n",
    "\n",
    "def swap_subtrees(node1: OperatorNode, node2: OperatorNode):\n",
    "    node1.left, node2.left = node2.left.clone(), node1.left.clone()\n",
    "    if node1.right is not None:\n",
    "        if node2.right is not None:\n",
    "            node1.right, node2.right = node2.right.clone(), node1.right.clone()\n",
    "        else:\n",
    "            node2.right = node1.right.clone()\n",
    "            node1.right = None\n",
    "    else:\n",
    "        if node2.right is not None:\n",
    "            node1.right = node2.right.clone()\n",
    "            node2.right = None\n",
    "\n",
    "    node1.operator_symbol, node2.operator_symbol = node2.operator_symbol, node1.operator_symbol\n",
    "    node1.function, node2.function = node2.function, node1.function\n",
    "\n",
    "\n",
    "def swap_operands(node1: OperandNode, node2: OperandNode):\n",
    "    node1.value, node2.value = node2.value, node1.value\n",
    "\n",
    "\n",
    "def replace_subtree(ind1, ind2, subtree1: Node, subtree2: Node):\n",
    "    if subtree1 is None or subtree2 is None:\n",
    "        raise ValueError(\"Cannot replace subtree: node is None.\")\n",
    "\n",
    "    parent1 = find_parent(ind1, subtree1)\n",
    "    parent2 = find_parent(ind2, subtree2)\n",
    "\n",
    "    if parent1 is None or parent2 is None:\n",
    "        return\n",
    "\n",
    "    if parent1.left is subtree1 and parent2.left is subtree2:\n",
    "        parent1.left = subtree2.clone()\n",
    "        parent2.left = subtree1.clone()\n",
    "    elif parent1.right is subtree1 and parent2.right is subtree2:\n",
    "        parent1.right = subtree2.clone()\n",
    "        parent2.right = subtree1.clone()\n",
    "    elif parent1.left is subtree1 and parent2.right is subtree2:\n",
    "        parent1.left = subtree2.clone()\n",
    "        parent2.right = subtree1.clone()\n",
    "    elif parent1.right is subtree1 and parent2.left is subtree2:\n",
    "        parent1.right = subtree2.clone()\n",
    "        parent2.left = subtree1.clone()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "63dccb979fea7326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.215253Z",
     "start_time": "2025-01-18T14:17:46.202283Z"
    }
   },
   "source": [
    "def find_parent(root: Node, target: Node, parent: Node = None) -> Node | None:\n",
    "    if root is target:\n",
    "        return parent\n",
    "\n",
    "    if isinstance(root, OperatorNode):\n",
    "        if root.left:\n",
    "            found = find_parent(root.left, target, root)\n",
    "            if found:\n",
    "                return found\n",
    "        if root.right:\n",
    "            found = find_parent(root.right, target, root)\n",
    "            if found:\n",
    "                return found\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def replace_child(root: Node, old_child: Node, new_child: Node) -> None:\n",
    "    if not isinstance(root, OperatorNode):\n",
    "        return\n",
    "\n",
    "    if root.left is old_child:\n",
    "        root.left = new_child\n",
    "        return\n",
    "    if root.right is old_child:\n",
    "        root.right = new_child\n",
    "        return\n",
    "\n",
    "    # Recursively check the children\n",
    "    if root.left:\n",
    "        replace_child(root.left, old_child, new_child)\n",
    "    if root.right:\n",
    "        replace_child(root.right, old_child, new_child)\n",
    "\n",
    "\n",
    "def mutate(individual: Node, max_depth: int, mutation_rate: float, n_variables: int) -> Node:\n",
    "    if random.random() >= mutation_rate:\n",
    "        return individual  # No mutation occurs\n",
    "\n",
    "    # Clone the individual to avoid modifying the original\n",
    "    individual = individual.clone()\n",
    "\n",
    "    # Get all nodes in the tree\n",
    "    nodes = get_all_nodes(individual)\n",
    "    if not nodes:\n",
    "        raise ValueError(\"Cannot mutate: The tree has no nodes.\")\n",
    "\n",
    "    # Select a random node for mutation\n",
    "    mutate_node = random.choice(nodes)\n",
    "    while mutate_node is None:\n",
    "        mutate_node = random.choice(nodes)\n",
    "\n",
    "    # Apply mutation strategies\n",
    "    mutation_type = random.choice([\"shrink\", \"subtree_replacement\", \"hoist\", \"tweak\"])\n",
    "    if mutation_type == \"shrink\":\n",
    "        return apply_shrink_mutation(individual, mutate_node, n_variables)\n",
    "    elif mutation_type == \"subtree_replacement\" and max_depth - mutate_node.depth > 1:\n",
    "        new_subtree = generate_random_tree(max_depth - mutate_node.depth, n_variables, mutate_node.depth)\n",
    "        replace(individual, mutate_node, new_subtree)\n",
    "    elif mutation_type == \"hoist\":\n",
    "        return apply_hoist_mutation(individual, mutate_node)\n",
    "    elif mutation_type == \"tweak\":\n",
    "        tweak(mutate_node, n_variables)\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def apply_shrink_mutation(individual: Node, mutate_node: Node, n_variables: int) -> Node:\n",
    "    # Find the parent of the mutate_node\n",
    "    parent = find_parent(individual, mutate_node)\n",
    "\n",
    "    # Generate a terminal node (variable or constant)\n",
    "    terminal = OperandNode(\n",
    "        value=random.choice([random.uniform(-10, 10), f\"x_{random.randint(0, n_variables - 1)}\"]),\n",
    "        depth=mutate_node.depth  # Preserve depth for consistency\n",
    "    )\n",
    "\n",
    "    # Replace the mutate_node with the terminal node\n",
    "    if parent:\n",
    "        replace_child(parent, mutate_node, terminal)\n",
    "    else:\n",
    "        # If no parent, mutate_node is the root, replace the root directly\n",
    "        individual = terminal\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def replace(individual, node: Node, new_subtree: Node):\n",
    "    if node is None or new_subtree is None:\n",
    "        raise ValueError(\"Cannot replace subtree: node is None.\")\n",
    "\n",
    "    parent = find_parent(individual, node)\n",
    "\n",
    "    if parent is None:\n",
    "        return\n",
    "\n",
    "    if parent.left is node:\n",
    "        parent.left = new_subtree.clone()\n",
    "    elif parent.right is node:\n",
    "        parent.right = new_subtree.clone()\n",
    "\n",
    "\n",
    "def apply_hoist_mutation(individual: Node, mutate_node: Node) -> Node:\n",
    "    # Ensure the mutate_node has at least one child to hoist\n",
    "    if not isinstance(mutate_node, OperatorNode) or not mutate_node.left:\n",
    "        return individual  # No hoist possible, return unchanged\n",
    "\n",
    "    # Select the subtree to promote (left child by default)\n",
    "    hoisted_subtree = mutate_node.left\n",
    "\n",
    "    # Find the parent of the mutate_node\n",
    "    parent = find_parent(individual, mutate_node)\n",
    "\n",
    "    if parent:\n",
    "        # Replace the mutate_node with the hoisted subtree in the parent's reference\n",
    "        replace_child(parent, mutate_node, hoisted_subtree)\n",
    "    else:\n",
    "        # If the mutate_node is the root, replace the entire tree\n",
    "        individual = hoisted_subtree\n",
    "\n",
    "    return individual\n",
    "\n",
    "\n",
    "def tweak(node: Node, n_variables: int):\n",
    "    if isinstance(node, OperatorNode):\n",
    "        mutate_operator(node)\n",
    "    elif isinstance(node, OperandNode):\n",
    "        mutate_operand(node, n_variables)\n",
    "\n",
    "\n",
    "def mutate_operator(node: OperatorNode):\n",
    "    available_operators = []\n",
    "    if node.operator_symbol not in OperatorNode.BINARY_OPERATORS:\n",
    "        # Unary operator\n",
    "        available_operators = [op for op in OperatorNode.OPERATORS.keys() if op not in OperatorNode.BINARY_OPERATORS]\n",
    "        available_operators.remove(node.operator_symbol)\n",
    "    else:\n",
    "        # Binary operator\n",
    "        available_operators = [op for op in OperatorNode.BINARY_OPERATORS]\n",
    "        available_operators.remove(node.operator_symbol)\n",
    "\n",
    "    node.operator_symbol = random.choice(available_operators)\n",
    "    node.function = OperatorNode.OPERATORS[node.operator_symbol]\n",
    "\n",
    "\n",
    "def mutate_operand(node: OperandNode, n_variables: int):\n",
    "    if isinstance(node.value, float):\n",
    "        # Mutate constant value slightly\n",
    "        node.value += random.uniform(-1, 1)\n",
    "    elif isinstance(node.value, str) and node.value.startswith('x_'):\n",
    "        # Change the variable index\n",
    "        node.value = f\"x_{random.randint(0, n_variables - 1)}\""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.235543Z",
     "start_time": "2025-01-18T14:17:46.226983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simplify_expression(node: Node) -> Node:\n",
    "    if isinstance(node, OperandNode):\n",
    "        return node\n",
    "\n",
    "    if isinstance(node, OperatorNode):\n",
    "        # Recursively simplify left and right subtrees\n",
    "        node.left = simplify_expression(node.left)\n",
    "        if node.right:\n",
    "            node.right = simplify_expression(node.right)\n",
    "\n",
    "        # Simplify based on operator type\n",
    "        if node.operator_symbol in OperatorNode.BINARY_OPERATORS:\n",
    "            node = simplify_binary_operator(node)\n",
    "        else:\n",
    "            node = simplify_unary_operator(node)\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "def simplify_binary_operator(node: OperatorNode) -> Node:\n",
    "    if isinstance(node.left, OperandNode) and isinstance(node.right, OperandNode):\n",
    "        if isinstance(node.left.value, float) and isinstance(node.right.value, float):\n",
    "            # Both children are constants; compute the result\n",
    "            return OperandNode(node.function(node.left.value, node.right.value))\n",
    "\n",
    "    # Apply simplification rules for binary operators\n",
    "    if node.operator_symbol == '+':\n",
    "        if isinstance(node.left, OperandNode) and node.left.value == 0:\n",
    "            return node.right\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 0:\n",
    "            return node.left\n",
    "    elif node.operator_symbol == '*':\n",
    "        if isinstance(node.left, OperandNode) and node.left.value == 1:\n",
    "            return node.right\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 1:\n",
    "            return node.left\n",
    "        if isinstance(node.left, OperandNode) and node.left.value == 0:\n",
    "            return OperandNode(0)\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 0:\n",
    "            return OperandNode(0)\n",
    "    elif node.operator_symbol == '-':\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 0:\n",
    "            return node.left\n",
    "        if isinstance(node.left, OperandNode) and isinstance(node.right, OperandNode) and node.left.value == node.right.value:\n",
    "            return OperandNode(0)\n",
    "    elif node.operator_symbol == '/':\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 1:\n",
    "            return node.left\n",
    "        if isinstance(node.left, OperandNode) and isinstance(node.right, OperandNode) and node.left.value == node.right.value:\n",
    "            return OperandNode(1)\n",
    "    elif node.operator_symbol == '**':\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 1:\n",
    "            return node.left\n",
    "        if isinstance(node.right, OperandNode) and node.right.value == 0:\n",
    "            return OperandNode(1)\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "def simplify_unary_operator(node: OperatorNode) -> Node:\n",
    "    if isinstance(node.left, OperandNode):\n",
    "        if isinstance(node.left.value, float):\n",
    "            # Compute the result for unary operators\n",
    "            return OperandNode(node.function(node.left.value))\n",
    "\n",
    "    return node\n"
   ],
   "id": "c15c95e24f83299d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.256898Z",
     "start_time": "2025-01-18T14:17:46.253218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trim_population(population: list[Node]) -> list[Node]:\n",
    "    unique_individuals = []\n",
    "    seen_hashes = set()\n",
    "\n",
    "    for ind in population:\n",
    "        # Use a hash of the string representation for uniqueness\n",
    "        ind_hash = hash(str(ind))\n",
    "        if ind_hash not in seen_hashes:\n",
    "            seen_hashes.add(ind_hash)\n",
    "            unique_individuals.append(ind)\n",
    "\n",
    "    return unique_individuals"
   ],
   "id": "d85968e6d990d69a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "324decddc9a183ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:17:46.283454Z",
     "start_time": "2025-01-18T14:17:46.270462Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "def genetic_programming(\n",
    "        X, y,\n",
    "        pop_size,\n",
    "        generations,\n",
    "        max_depth,\n",
    "        crossover_rate,\n",
    "        mutation_rate,\n",
    "        elitism=True,\n",
    "        elitism_size=3,\n",
    "        max_no_improvement=5,\n",
    "        verbose=True,\n",
    "):\n",
    "    start_time = time.time()\n",
    "\n",
    "    n_variables = len(X[0])\n",
    "\n",
    "    population = initialize_population(pop_size, n_variables, max_depth)\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        init_pop_time = time.time()\n",
    "        print(f\"Population Init Time: {init_pop_time - start_time:.6f}\")\n",
    "\n",
    "    best_fitness_values = []\n",
    "    best_individuals = []\n",
    "\n",
    "    gens_without_improvement = 0\n",
    "\n",
    "    for gen in range(generations):\n",
    "        clear_cache()\n",
    "        init_pop_time = time.time()\n",
    "\n",
    "        objectives = Parallel(n_jobs=-1)(delayed(get_objectives)(ind, X, y) for ind in population)\n",
    "        objectives_dict = {ind: (mse, complexity) for ind, mse, complexity in sorted(objectives, key=lambda x: (x[1], x[2]))}\n",
    "\n",
    "        if verbose:\n",
    "            fitnesses_evaluation_time = time.time()\n",
    "            print(f\"Fitness Evaluation Time: {fitnesses_evaluation_time - init_pop_time:.6f}\")\n",
    "\n",
    "        # Track the best individual\n",
    "        best_individual = list(objectives_dict.keys())[0]\n",
    "        best_fitness = objectives_dict[best_individual][0]\n",
    "\n",
    "        if len(best_fitness_values) > 0 and best_fitness_values[-1] == best_fitness:\n",
    "            gens_without_improvement += 1\n",
    "        else:\n",
    "            gens_without_improvement = 0\n",
    "\n",
    "        best_fitness_values.append(best_fitness)\n",
    "        best_individuals.append(best_individual)\n",
    "\n",
    "        print(f\"Generation {gen+1}: Best Fitness = {best_fitness:.6f}\")\n",
    "        if best_fitness < 0.0001:\n",
    "            return best_individual, best_fitness, best_fitness_values\n",
    "\n",
    "        # Select individuals for the next generation\n",
    "        selected = multi_objective_selection(objectives_dict)\n",
    "        if verbose:\n",
    "            selection_time = time.time()\n",
    "            print(f\"Selection Time: {selection_time - fitnesses_evaluation_time:.6f}\")\n",
    "\n",
    "        # Create next generation\n",
    "        next_generation = []\n",
    "\n",
    "        # Elitism\n",
    "        if elitism:\n",
    "            next_generation.extend(objectives_dict.keys()[:elitism_size])\n",
    "\n",
    "        if gens_without_improvement > max_no_improvement:\n",
    "            if elitism:\n",
    "                next_generation.extend(objectives_dict.keys()[elitism_size:pop_size * 0.6])\n",
    "            else:\n",
    "                next_generation.extend(objectives_dict.keys()[:pop_size * 0.6])\n",
    "\n",
    "            next_generation.extend(initialize_population(pop_size - len(next_generation), n_variables, max_depth))\n",
    "            gens_without_improvement = 0\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            elitism_time = time.time()\n",
    "            print(f\"Elitism Time: {elitism_time - selection_time:.6f}\")\n",
    "\n",
    "        # Generate offspring\n",
    "        while len(next_generation) < pop_size:\n",
    "            if random.random() < crossover_rate:\n",
    "                parent1, parent2 = random.sample(selected, 2)\n",
    "                offspring1, offspring2 = crossover(parent1, parent2)\n",
    "                next_generation.append(simplify_expression(offspring1))\n",
    "                next_generation.append(simplify_expression(offspring2))\n",
    "            else:\n",
    "                individual = random.choice(selected)\n",
    "                mutated = mutate(individual, max_depth, mutation_rate, n_variables)\n",
    "                next_generation.append(simplify_expression(mutated))\n",
    "\n",
    "        if verbose:\n",
    "            new_generation_time = time.time()\n",
    "            print(f\"New Generation Time: {new_generation_time - elitism_time:.6f}\")\n",
    "\n",
    "        next_generation = trim_population(next_generation)\n",
    "        if verbose:\n",
    "            trimming_time = time.time()\n",
    "            print(f\"Trimming Time: {trimming_time - new_generation_time:.6f}\")\n",
    "\n",
    "        if random.random() < 0.2:\n",
    "            if verbose:\n",
    "                print(\"Trimming Population\")\n",
    "\n",
    "            next_generation = next_generation[:int(0.6 * pop_size)]\n",
    "\n",
    "        while len(next_generation) < pop_size:\n",
    "            next_generation.append(generate_random_tree(max_depth, n_variables))\n",
    "\n",
    "        if verbose:\n",
    "            random_generation_time = time.time()\n",
    "            print(f\"Random Generation Time: {random_generation_time - trimming_time:.6f}\")\n",
    "\n",
    "        population = next_generation\n",
    "\n",
    "\n",
    "    objectives = Parallel(n_jobs=-1)(delayed(get_objectives)(ind, X, y) for ind in population)\n",
    "    objectives_dict = {}\n",
    "    for ind, mse, complexity in objectives:\n",
    "        objectives_dict[ind] = (mse, complexity)\n",
    "\n",
    "    objectives_dict = {ind: objectives_dict[ind] for ind in sorted(objectives_dict.keys(), key=lambda ind: objectives_dict[ind])}\n",
    "\n",
    "    best_individual = list(objectives_dict.keys())[0]\n",
    "    best_fitness = objectives_dict[best_individual][0]\n",
    "\n",
    "    best_fitness_values.append(best_fitness)\n",
    "    best_individuals.append(best_individual)\n",
    "\n",
    "    # Final evaluation\n",
    "    best_fitness = min(best_fitness_values)\n",
    "    best_index = best_fitness_values.index(best_fitness)\n",
    "    best_individual = best_individuals[best_index]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nBest Overall Fitness: {best_fitness:.6f}\")\n",
    "\n",
    "    return best_individual, best_fitness, best_fitness_values"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "be4c03b33b080dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T19:46:19.994971Z",
     "start_time": "2025-01-18T19:46:19.988281Z"
    }
   },
   "source": [
    "def run():\n",
    "    np.random.seed(41)\n",
    "    random.seed(41)\n",
    "    problem = np.load('data/problem_8.npz')\n",
    "    X = np.array(problem['x'])\n",
    "    y = np.array(problem['y'])\n",
    "\n",
    "    # Run Genetic Programming\n",
    "    best_expr, best_fit, best_fitness_values = genetic_programming(\n",
    "        X.T, y,\n",
    "        pop_size=500,\n",
    "        generations=500,\n",
    "        max_depth=5,\n",
    "        crossover_rate=0.4,\n",
    "        mutation_rate=0.8,\n",
    "        elitism=True,\n",
    "        elitism_size=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest Expression: {best_expr}\")\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = np.array([best_expr.evaluate(x) for x in X.T])\n",
    "\n",
    "    # Visualize the results considering X has a variable number of arrays inside it\n",
    "    if X.shape[0] == 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(X[0], y, color='blue', label='Data', alpha=0.6)\n",
    "        plt.plot(X[0], y_pred, color='red', label='Best GP Expression')\n",
    "        plt.legend()\n",
    "        plt.title('Symbolic Regression using Genetic Programming')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(X[0], X[1], y, color='blue', label='Data', alpha=0.6)\n",
    "        ax.plot_trisurf(X[0], X[1], y_pred, color='red', alpha=0.6)\n",
    "        ax.set_xlabel('x_0')\n",
    "        ax.set_ylabel('x_1')\n",
    "        ax.set_zlabel('y')\n",
    "        ax.set_title('Symbolic Regression using Genetic Programming (3D Visualization)')\n",
    "        plt.legend()\n",
    "        plt.title(f'Symbolic Regression using Genetic Programming')\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(best_fitness_values, color='blue', label='Best Fitness')\n",
    "    plt.title('Best Fitness over Generations')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Best Fitness')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "11ba7956d5f20e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T23:08:50.858159Z",
     "start_time": "2025-01-18T19:46:21.103277Z"
    }
   },
   "source": "run()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = 22667096.904650\n",
      "Generation 2: Best Fitness = 15327540.516692\n",
      "Generation 3: Best Fitness = 15327540.516692\n",
      "Generation 4: Best Fitness = 15327540.516692\n",
      "Generation 5: Best Fitness = 15327540.516692\n",
      "Generation 6: Best Fitness = 15327540.516692\n",
      "Generation 7: Best Fitness = 15327540.516692\n",
      "Generation 8: Best Fitness = 15327540.516692\n",
      "Generation 9: Best Fitness = 15327540.516692\n",
      "Generation 10: Best Fitness = 15327540.516692\n",
      "Generation 11: Best Fitness = 15327540.516692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 12: Best Fitness = 15327540.516692\n",
      "Generation 13: Best Fitness = 15327540.516692\n",
      "Generation 14: Best Fitness = 15327540.516692\n",
      "Generation 15: Best Fitness = 15327540.516692\n",
      "Generation 16: Best Fitness = 15327540.516692\n",
      "Generation 17: Best Fitness = 15327540.516692\n",
      "Generation 18: Best Fitness = 15327540.516692\n",
      "Generation 19: Best Fitness = 14004834.794078\n",
      "Generation 20: Best Fitness = 14004834.794078\n",
      "Generation 21: Best Fitness = 14004834.794078\n",
      "Generation 22: Best Fitness = 14004834.794078\n",
      "Generation 23: Best Fitness = 14004834.794078\n",
      "Generation 24: Best Fitness = 13682683.260043\n",
      "Generation 25: Best Fitness = 13682683.260043\n",
      "Generation 26: Best Fitness = 13682683.260043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 27: Best Fitness = 13682683.260043\n",
      "Generation 28: Best Fitness = 13682683.260043\n",
      "Generation 29: Best Fitness = 13682683.260043\n",
      "Generation 30: Best Fitness = 13682683.260043\n",
      "Generation 31: Best Fitness = 13682683.260043\n",
      "Generation 32: Best Fitness = 13682683.260043\n",
      "Generation 33: Best Fitness = 13682683.260043\n",
      "Generation 34: Best Fitness = 13682683.260043\n",
      "Generation 35: Best Fitness = 13682683.260043\n",
      "Generation 36: Best Fitness = 13682683.260043\n",
      "Generation 37: Best Fitness = 13682683.260043\n",
      "Generation 38: Best Fitness = 13682683.260043\n",
      "Generation 39: Best Fitness = 13682683.260043\n",
      "Generation 40: Best Fitness = 13682683.260043\n",
      "Generation 41: Best Fitness = 13682683.260043\n",
      "Generation 42: Best Fitness = 13682683.260043\n",
      "Generation 43: Best Fitness = 13682683.260043\n",
      "Generation 44: Best Fitness = 13682683.260043\n",
      "Generation 45: Best Fitness = 13682683.260043\n",
      "Generation 46: Best Fitness = 13682683.260043\n",
      "Generation 47: Best Fitness = 13682683.260043\n",
      "Generation 48: Best Fitness = 13682683.260043\n",
      "Generation 49: Best Fitness = 13682683.260043\n",
      "Generation 50: Best Fitness = 12255216.927055\n",
      "Generation 51: Best Fitness = 12255216.927055\n",
      "Generation 52: Best Fitness = 12255216.927055\n",
      "Generation 53: Best Fitness = 12255216.927055\n",
      "Generation 54: Best Fitness = 12255216.927055\n",
      "Generation 55: Best Fitness = 12255216.927055\n",
      "Generation 56: Best Fitness = 12255216.927055\n",
      "Generation 57: Best Fitness = 12255216.927055\n",
      "Generation 58: Best Fitness = 12254693.260389\n",
      "Generation 59: Best Fitness = 12254693.260389\n",
      "Generation 60: Best Fitness = 12254693.260389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 61: Best Fitness = 12254035.880425\n",
      "Generation 62: Best Fitness = 12254035.880425\n",
      "Generation 63: Best Fitness = 12231918.864833\n",
      "Generation 64: Best Fitness = 12231918.864833\n",
      "Generation 65: Best Fitness = 12231918.864833\n",
      "Generation 66: Best Fitness = 11435358.826042\n",
      "Generation 67: Best Fitness = 11435358.826042\n",
      "Generation 68: Best Fitness = 11435358.826042\n",
      "Generation 69: Best Fitness = 11435358.826042\n",
      "Generation 70: Best Fitness = 11435358.826042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 71: Best Fitness = 11435358.826042\n",
      "Generation 72: Best Fitness = 11435358.826042\n",
      "Generation 73: Best Fitness = 11435358.826042\n",
      "Generation 74: Best Fitness = 11435358.826042\n",
      "Generation 75: Best Fitness = 11435358.826042\n",
      "Generation 76: Best Fitness = 11435358.826042\n",
      "Generation 77: Best Fitness = 11435358.826042\n",
      "Generation 78: Best Fitness = 11435358.826042\n",
      "Generation 79: Best Fitness = 11435358.826042\n",
      "Generation 80: Best Fitness = 11399558.636453\n",
      "Generation 81: Best Fitness = 11399558.636453\n",
      "Generation 82: Best Fitness = 11399558.636453\n",
      "Generation 83: Best Fitness = 11326668.497599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 84: Best Fitness = 11326668.497599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 85: Best Fitness = 11326668.497599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 86: Best Fitness = 11321745.807584\n",
      "Generation 87: Best Fitness = 11321745.807584\n",
      "Generation 88: Best Fitness = 11321745.807584\n",
      "Generation 89: Best Fitness = 11134643.488144\n",
      "Generation 90: Best Fitness = 11134643.488144\n",
      "Generation 91: Best Fitness = 11134643.488144\n",
      "Generation 92: Best Fitness = 11134643.488144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/psm35sh503x7y51vnw94qbzw0000gn/T/ipykernel_19030/4114134282.py:20: RuntimeWarning: overflow encountered in scalar divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 93: Best Fitness = 11134643.488144\n",
      "Generation 94: Best Fitness = 11134643.488144\n",
      "Generation 95: Best Fitness = 11134643.488144\n",
      "Generation 96: Best Fitness = 11134643.488144\n",
      "Generation 97: Best Fitness = 11134643.488144\n",
      "Generation 98: Best Fitness = 11134643.488144\n",
      "Generation 99: Best Fitness = 11134643.488144\n",
      "Generation 100: Best Fitness = 11134643.488144\n",
      "Generation 101: Best Fitness = 11134643.488144\n",
      "Generation 102: Best Fitness = 11134643.488144\n",
      "Generation 103: Best Fitness = 11134643.488144\n",
      "Generation 104: Best Fitness = 11134643.488144\n",
      "Generation 105: Best Fitness = 11134643.488144\n",
      "Generation 106: Best Fitness = 11134643.488144\n",
      "Generation 107: Best Fitness = 11134643.488144\n",
      "Generation 108: Best Fitness = 11134643.488144\n",
      "Generation 109: Best Fitness = 11134643.488144\n",
      "Generation 110: Best Fitness = 11134643.488144\n",
      "Generation 111: Best Fitness = 11134643.488144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1703\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m-> 1703\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_abort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1704\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1614\u001B[0m, in \u001B[0;36mParallel._abort\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1613\u001B[0m     ensure_ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend\n\u001B[0;32m-> 1614\u001B[0m     \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1615\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/_parallel_backends.py:620\u001B[0m, in \u001B[0;36mLokyBackend.abort_everything\u001B[0;34m(self, ensure_ready)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001B[39;00m\n\u001B[1;32m    619\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/executor.py:75\u001B[0m, in \u001B[0;36mMemmappingExecutor.terminate\u001B[0;34m(self, kill_workers)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001B[39;00m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001B[39;00m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001B[39;00m\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;66;03m# on by the resource_tracker.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:1303\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[0;34m(self, wait, kill_workers)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _global_shutdown_lock:\n\u001B[0;32m-> 1303\u001B[0m     \u001B[43mexecutor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1304\u001B[0m     _threads_wakeups\u001B[38;5;241m.\u001B[39mpop(executor_manager_thread, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/threading.py:1149\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1149\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1151\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/threading.py:1169\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1170\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 9\u001B[0m, in \u001B[0;36mrun\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(problem[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Run Genetic Programming\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m best_expr, best_fit, best_fitness_values \u001B[38;5;241m=\u001B[39m \u001B[43mgenetic_programming\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcrossover_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmutation_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43melitism\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43melitism_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest Expression: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_expr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Generate predictions\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[13], line 38\u001B[0m, in \u001B[0;36mgenetic_programming\u001B[0;34m(X, y, pop_size, generations, max_depth, crossover_rate, mutation_rate, elitism, elitism_size, max_no_improvement, filename, verbose)\u001B[0m\n\u001B[1;32m     35\u001B[0m clear_cache()\n\u001B[1;32m     36\u001B[0m init_pop_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 38\u001B[0m objectives \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_objectives\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mind\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpopulation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m objectives_dict \u001B[38;5;241m=\u001B[39m {ind: (mse, complexity) \u001B[38;5;28;01mfor\u001B[39;00m ind, mse, complexity \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(objectives, key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: (x[\u001B[38;5;241m1\u001B[39m], x[\u001B[38;5;241m2\u001B[39m]))}\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1711\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1709\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_running \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1710\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m detach_generator_exit:\n\u001B[0;32m-> 1711\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_terminate_and_reset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(_remaining_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1714\u001B[0m     batched_results \u001B[38;5;241m=\u001B[39m _remaining_outputs\u001B[38;5;241m.\u001B[39mpopleft()\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/parallel.py:1386\u001B[0m, in \u001B[0;36mParallel._terminate_and_reset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend:\n\u001B[0;32m-> 1386\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/_parallel_backends.py:610\u001B[0m, in \u001B[0;36mLokyBackend.terminate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    606\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    607\u001B[0m         \u001B[38;5;66;03m# Don't terminate the workers as we want to reuse them in later\u001B[39;00m\n\u001B[1;32m    608\u001B[0m         \u001B[38;5;66;03m# calls, but cleanup the temporary resources that the Parallel call\u001B[39;00m\n\u001B[1;32m    609\u001B[0m         \u001B[38;5;66;03m# created. This 'hack' requires a private, low-level operation.\u001B[39;00m\n\u001B[0;32m--> 610\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_temp_folder_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_clean_temporary_resources\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    611\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m    612\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    615\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_batch_stats()\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/_memmapping_reducer.py:641\u001B[0m, in \u001B[0;36mTemporaryResourcesManager._clean_temporary_resources\u001B[0;34m(self, context_id, force, allow_non_empty)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;66;03m# Clean up the folder if possible, either if it is empty or\u001B[39;00m\n\u001B[1;32m    639\u001B[0m \u001B[38;5;66;03m# if none of the files in it are in used and allow_non_empty.\u001B[39;00m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 641\u001B[0m     \u001B[43mdelete_folder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    642\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_non_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_non_empty\u001B[49m\n\u001B[1;32m    643\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    644\u001B[0m     \u001B[38;5;66;03m# Forget the folder once it has been deleted\u001B[39;00m\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_temp_folders\u001B[38;5;241m.\u001B[39mpop(context_id, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/CI/lib/python3.12/site-packages/joblib/disk.py:136\u001B[0m, in \u001B[0;36mdelete_folder\u001B[0;34m(folder_path, onerror, allow_non_empty)\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m err_count \u001B[38;5;241m>\u001B[39m RM_SUBDIRS_N_RETRY:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;66;03m# the folder cannot be deleted right now. It maybe\u001B[39;00m\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;66;03m# because some temporary files have not been deleted\u001B[39;00m\n\u001B[1;32m    134\u001B[0m         \u001B[38;5;66;03m# yet.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m--> 136\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRM_SUBDIRS_RETRY_TIME\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T18:41:06.943991Z",
     "start_time": "2025-01-18T18:41:06.941180Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9706b1f7e198dcac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
